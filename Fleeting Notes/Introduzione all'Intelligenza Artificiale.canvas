{
	"nodes":[
		{"id":"b8de086c89a3e128","type":"group","x":-11504,"y":-2560,"width":3680,"height":3760,"label":"Agenti intelligenti"},
		{"id":"eb585b966719db27","type":"group","x":-6480,"y":-1660,"width":4220,"height":2360,"label":"Strategie di ricerca"},
		{"id":"a7cb16c6b4cd765f","type":"group","x":-8768,"y":1359,"width":2959,"height":3019,"label":"Agenti risolutori di problemi "},
		{"id":"d6dc4342ae039ab4","type":"group","x":-11199,"y":-2021,"width":1855,"height":1941,"label":"Agente razionale"},
		{"id":"ee115b0e27b3b2e8","type":"group","x":-15040,"y":-2901,"width":1700,"height":1541,"label":"Agenti"},
		{"id":"4016df7184ee7a54","type":"group","x":-520,"y":-480,"width":1240,"height":1840,"label":"Storia dell'Intelligenza Artificiale"},
		{"id":"f34aa83abfd1300e","type":"group","x":-1920,"y":-480,"width":1020,"height":1420,"label":"Introduzione"},
		{"id":"626ef1ccf6e5e6e5","type":"text","text":"Possono assumere valori discreti o continui\n\n lo stato: solo un numero finito di stati\n\n il tempo\n\n le percezioni\n\n le azioni\n\n Si può cercare di astrarre e lavorare in stati discreti anche se nelal\n\nrealtà non è così\n\nEsempio guida del taxi è un problema con stato e tempo continui … ma\n\nnoi possiamo vederli per punti chiave della strada","x":-14740,"y":-900,"width":310,"height":752},
		{"id":"b6764cefd3dd07f1","type":"text","text":" Deterministico\n\nSe lo stato successivo è completamente determinato dallo stato corrente e\n\ndall’azione. Esempio: scacchi\n\n Stocastico\n\nEsistono elementi di incertezza con associata probabilità. Esempi: guida,\n\ntiro in porta\n\n Non deterministico\n\nSi tiene traccia di più stati possibili risultato dell’azione (ma non in base\n\nad una probabilità)","x":-15620,"y":-900,"width":380,"height":608},
		{"id":"af1eac51eb7b1fc7","type":"text","text":" Statico\n\nIl mondo non cambia mentre l’ agente decide l’azione\n\n Dinamico\n\nCambia nel tempo, va osservata la contingenza\n\nTardare equivale a non agire\n\n Semi-dinamico\n\nL’ambiente non cambia ma la valutazione dell’agente sì.\n\nEsempio: Scacchi con timer.","x":-15200,"y":-900,"width":430,"height":502},
		{"id":"e99387765a9dbcc2","type":"text","text":"Noto/ignoto\n\n Distinzione riferita allo stato di conoscenza dell’agente\n\n L’agente conosce l’ambiente oppure deve compiere azioni esplorative?\n\n Noto diverso da osservabile (e.g. carte coperte, regole note)\n\nAmbienti reali: parzialmente oss","x":-14380,"y":-900,"width":370,"height":560},
		{"id":"6418a73b07f7b097","type":"text","text":"Nel settore dell'Intelligenza Artificiale, un agente è un sistema in grado di scrutare l'ambiente circostante con dei sensori e agire su di esso tramite degli attuatori.\nÈ possibile definire diversi tipi di agenti in base alle loro caratteristiche:","x":-15020,"y":-2881,"width":280,"height":251},
		{"id":"3c1398ccff64db63","type":"text","text":"Agente reattivo\n---\nRisponde in maniera reattiva allo stimolo fornito, ad esempio un temrostato che regola la temperatura in casa.","x":-14600,"y":-2881,"width":320,"height":195},
		{"id":"ca4c1c1d164f0da4","type":"text","text":"Agente proattivo\n---\nVanno oltre la reattività, basandosi su una conoscenza approfondita del contesto e cercano di risolvere problemi e offrire soluzioni al di fuori dello stimolo, ad esempio Alexa o Siri.","x":-14600,"y":-2656,"width":320,"height":226},
		{"id":"7f2d3c8bb821c29e","type":"text","text":"**Agenti Multi-Agente:**\n---\nAgenti che competono o collaborano al raggiungimento di un obiettivo comune, ad esempio il sistema responsabile della guida autonoma di una vettura","x":-14600,"y":-2401,"width":320,"height":321},
		{"id":"616a716da8e83135","type":"text","text":"4. **Agenti basati sull'utilità:** Gli agenti basati sull'utilità prendono decisioni basate su una valutazione delle conseguenze delle loro azioni. Assegnano un valore o un'importanza alle diverse azioni e scelgono quella che massimizza una funzione di utilità specifica. Questo tipo di agente è particolarmente utile quando ci sono molte scelte possibili e risultati incerti, e l'obiettivo è massimizzare un certo beneficio o vantaggio.","x":-14589,"y":-1216,"width":250,"height":60},
		{"id":"62356168bc82e293","type":"text","text":"Definizione\n---\nPer ogni sequenza di percezioni compie l'azione che massimizza il valore atteso della misura delle prestazioni, considerando le sue percezioni passate e la sua conoscenza pregressa","x":-11164,"y":-1980,"width":322,"height":324},
		{"id":"978773b970fed2b9","type":"text","text":"È in grado di apprendere e modificare il proprio comportamento con l'esperienza. Può migliorare esplorando, apprendendo aumentando autonomia per operare in ambienti differenti o mutevoli","x":-10709,"y":-1980,"width":250,"height":324},
		{"id":"a7a25b94ad9239b0","type":"text","text":"Descrizione PEAS\n---\nP: Performance\nE: Enviorment\nA: Actuators\nS: Sensors","x":-11164,"y":-1620,"width":322,"height":296},
		{"id":"f8b987ffd135f0bd","type":"text","text":"","x":-8017,"y":-968,"width":250,"height":60},
		{"id":"17e04cc6b652cee1","type":"text","text":"Formulazione\n---\nUn tale problema è definito da;\n1. Insieme di stati iniziali\n2. Insieme di operatori / funzioni successore $S(x)$\n3. Test obiettivo\n4. Funzione costo cammino\n>[!note] Per ciascuna azione viene specificato l'insieme di stati raggiunti da qualsiasi stato considerato. Un cammino collega insieme gli stati","x":-7289,"y":2632,"width":380,"height":440},
		{"id":"a253e24b36d5b006","type":"text","text":"Prolemi di contingenza\n----\nLe informazioni a disposizione sono;\n- Alcuni dati relativi alle conseguenze dei problemi sullo spazio degli stati, alcune azioni possono avere effetti dubbi\n- ==Non ho alcuna informazione sullo stato di partenza==\n\nUn problema è detto \"**con avversari**\" se la contingenza (imprevisto) è causata da un altro agente.","x":-7849,"y":3032,"width":420,"height":408},
		{"id":"3c9803641bc94e71","type":"text","text":"Spesso è necessario agire e verificare l'effetto della propria azione prima di avere trovato una soluzione\n\nSi sfruttano le informazioni supplementari trovate runtime per continuare a risolvere il problema","x":-6909,"y":3295,"width":420,"height":294},
		{"id":"1aefccf17e8aa852","type":"text","text":"Formulazione\n---\nL'agente deve costruire un intero albero di azioni piuttosto che una singola sequenza\n\n","x":-7289,"y":3444,"width":250,"height":224},
		{"id":"52b92ad7f97d4196","type":"text","text":"Proprietà dell'ambiente/problema","x":-10709,"y":-1620,"width":250,"height":296},
		{"id":"662c86d197cb743e","type":"text","text":"Conoscenza\n---\nGli agenti basati sulla conoscenza hanno una rappresentazione esplicita della conoscenza che può essere ragionata. Mantengono lo stato interno di conoscenza, ragionano su di esso, lo aggiornano ed eseguono azioni di conseguenza. Questi agenti agiscono in modo intelligente in base alle esigenze.","x":-7695,"y":-1520,"width":415,"height":178},
		{"id":"f075af17568f02a2","type":"text","text":"Knowledge-Based Agents\n---\n- Gli agenti basati sulla conoscenza sono quegli agenti che hanno la capacità di mantenere uno stato interno di conoscenza, ragionare su tale conoscenza, aggiornare la propria conoscenza dopo le osservazioni e agire. Questi agenti possono rappresentare il mondo con una certa rappresentazione formale e agire in modo intelligente.","x":-7695,"y":-1826,"width":415,"height":266},
		{"id":"f3b3e9c3ebf18a98","type":"text","text":"Tipi di problemi\n---\nIn base alle informazioni che possediamo sul problema.è possibile classificare quest ultimo in diverse categorie:\n- Problemi a stato singolo\n- Problemi a stati multipli\n- Prolemi di contingenza\n- Problemi di esplorazione","x":-8298,"y":1659,"width":359,"height":315},
		{"id":"ba813fab1efda65c","type":"text","text":"Problemi a stato singolo\n----\nLe informazioni a disposizione sono; \n- Stato di partenza del sistema \n- Impatto del problema sullo stato del sistema\n\nTramite i sensori, l'agente riceve informazioni sufficienti sullo stato in cui si trova\nL'agente può calcolare esattamente in quale stato sarà dopo qualsiasi sequenza di azioni\n\n","x":-7849,"y":1659,"width":420,"height":460},
		{"id":"2b0f00f9e2ed9114","type":"text","text":"Problemi a stati multipli\n---\nLe informazioni a disposizione sono;\n- Impatto del problema sullo stato del sistema\n- ==Non ho alcuna informazione sullo stato di partenza==\n\nAgente privo di sensori, non può scrutare lo spazio circostante, ogni azione potrebbe portarlo tra molti possibili stati successori\n\nOgni insieme viene chiamato stato credenza.","x":-7849,"y":2337,"width":420,"height":440},
		{"id":"df311ca290c21107","type":"text","text":"Formulazione\n---\nUn tale problema è definito da: \n1. Stato iniziale $x$\n2. Operatore / funzione successore $S(x)$\n3. Test obiettivo\n4. Funzione costo cammino","x":-7289,"y":1974,"width":380,"height":460},
		{"id":"0f0c42ee452422f5","type":"text","text":"Applizazioni\n---\nPuò essere applicato sia a problemi giocattolo che a problemi reali\n\n>[!note] Ci sono problemi che non possono essere. risolti con questo tipo di agente\n","x":-8689,"y":1458,"width":250,"height":300},
		{"id":"9c4a99074a66f325","type":"text","text":"Problemi di esplorazione\n---\nLe informazioni a disposizione sono:\n- Non si ha conoscenza né sullo stato del mondo né sugli effetti delle proprie azioni.\n\nL'agente deve ricavare tutte le informazioni in autonomia attraverso l’esperienza.\n\n> [!note] I problemi di esplorazione possono essere considerati casi estremi di problemi di contingenza\n\n\n-  La ricerca si svolge nel mondo reale e non in un modello: agire può comportare danni significativi per un agente privo di conoscenza\n    \n-  Se sopravvive, acquisisce conoscenza che può riusare per problemi successivi\n\n","x":-7849,"y":3525,"width":420,"height":498},
		{"id":"4cc3f971f9384c46","type":"text","text":"","x":-7461,"y":-1926,"width":250,"height":60},
		{"id":"1d39f1a4a8236e4e","type":"text","text":"Descrivendola in fatti semplici, un agente logico si basa su sue conoscenze di base e poi applica un metodo inferenziale per raggiungere altre informazioni sulla base di quelle che già possiede","x":-8360,"y":-1866,"width":415,"height":266},
		{"id":"dd5ba2bb29a6d18f","type":"text","text":"Il sistema di inferenza applica regole logiche alla Knowledge base per poter generare nuovi fatti sulla base delle conoscenze pregresse","x":-8360,"y":-1527,"width":411,"height":185},
		{"id":"b8422c253b707d5e","type":"text","text":"No, la descrizione in termini di PEAS non è direttamente utilizzata dagli agenti intelligenti, ma è uno strumento di progettazione e valutazione creato dagli sviluppatori o dagli ingegneri per definire chiaramente gli obiettivi, le prestazioni desiderate e l'ambiente di funzionamento del sistema intelligente.\n\nGli agenti intelligenti, che possono essere programmati o addestrati, utilizzano l'informazione fornita dalla descrizione PEAS durante la loro progettazione e implementazione per garantire che il loro comportamento sia allineato agli obiettivi e alle esigenze del compito specifico. Ad esempio, i progettisti di un agente razionale o basato sulla conoscenza utilizzeranno la descrizione PEAS per definire le regole, le strategie o la base di conoscenza necessaria per far funzionare l'agente in modo efficace nell'ambiente specificato.\n\nIn sintesi, la descrizione in PEAS è uno strumento di supporto per la progettazione e la comunicazione, ma non è utilizzata direttamente dagli agenti intelligenti durante il loro funzionamento. Gli agenti si basano sulla programmazione, sull'addestramento e sulla conoscenza incorporata per prendere decisioni e agire in conformità con gli obiettivi e le misure delle prestazioni specificate nella descrizione PEAS.","x":-9160,"y":-1866,"width":626,"height":467},
		{"id":"f436bf0c14132662","type":"text","text":"Approcci\n---\n- Approccio dichiarativo\n- Approccio procedurale","x":-7695,"y":-1300,"width":488,"height":249},
		{"id":"b284f33974a74b4a","type":"text","text":"","x":-7095,"y":-972,"width":250,"height":60},
		{"id":"98429e5d0128ee8e","type":"text","text":"1. **Semplici agenti riflessi:** Questi agenti prendono decisioni basate esclusivamente sulle informazioni percepite nell'ambiente in un determinato istante, senza considerare lo stato passato o le esperienze precedenti. Le loro azioni dipendono esclusivamente dalle condizioni presenti e dalle regole di reazione. Sono adatti per ambienti semplici e ben definiti.","x":-15960,"y":-2837,"width":380,"height":302},
		{"id":"3eb408339b841701","type":"text","text":"3. **Agenti basati su obiettivi:** Gli agenti basati su obiettivi sono in grado di definire obiettivi specifici e utilizzare strategie per raggiungerli. Possono pianificare le loro azioni in modo da massimizzare la probabilità di raggiungere l'obiettivo desiderato. Questi agenti possono essere adattabili e flessibili, ma richiedono una rappresentazione chiara degli obiettivi e delle priorità.","x":-15532,"y":-2401,"width":465,"height":280},
		{"id":"bb6b049e51ec47ad","type":"text","text":"4. **Agenti basati sull'utilità:** Gli agenti basati sull'utilità prendono decisioni basate su una valutazione delle conseguenze delle loro azioni. Assegnano un valore o un'importanza alle diverse azioni e scelgono quella che massimizza una funzione di utilità specifica. Questo tipo di agente è particolarmente utile quando ci sono molte scelte possibili e risultati incerti, e l'obiettivo è massimizzare un certo beneficio o vantaggio.","x":-16160,"y":-2401,"width":490,"height":440},
		{"id":"9fcf7e50b006416f","type":"text","text":"Preistoria\n---\n- Nascita dei calcolatori\n- Nel 1943 McCulloch e Pitts formulano la prima struttura di neurale formata da neuroni artificiali, dimostrarono che qualsiasi funzione computabile può essere rappresentata da qualche rete di neuroni, e che tutti i connettivi logici (“e”, “o”, ...) possono essere implementati da una semplice struttura neurale.\n\nNascita del termine\n---\n- Nel 1956 introdusse il termine \"Artificial Intelligence\" in un convegno tenuto al Dartmouth College nel New Hampshire","x":-485,"y":-440,"width":640,"height":390},
		{"id":"80598154a9bb1888","type":"text","text":"John McCarthy, Marvin Minski, Claude Shannon, Nathaniel Rochester","x":-485,"y":295,"width":381,"height":79},
		{"id":"3536d34be9bcffaf","type":"text","text":"Herbert Simon, Allen Newell","x":276,"y":295,"width":381,"height":79},
		{"id":"cc2724deb52c9e41","type":"text","text":"Sistema in grado di simulare ogni aspetto della mente umana","x":-485,"y":475,"width":381,"height":123},
		{"id":"c1feae09229e4a8a","type":"text","text":"Logic Theorist: Un sistemai n grado di dimostrare teoremi partendo dai principi della matematica","x":276,"y":475,"width":381,"height":123},
		{"id":"5e2d26a4d9bd0e8a","type":"text","text":"Sulle basi di Logic Theorist venne creato il General Problem Solver, operava su un dominio ristrettissimo di problemi ma utilizzando un approccio assimilabile a quello umano","x":-485,"y":775,"width":381,"height":139},
		{"id":"e0f409d4f08ae900","type":"text","text":"Nel 1959 McCarthy scrisse un articolo in cui descriveva un programma ideale chiamato \"Advice Taker\", definito come primo sistema completo, in quanto risolutore di problemi generici e non solo matematici","x":-485,"y":988,"width":381,"height":147},
		{"id":"fef80b7c87bac4c1","type":"text","text":"Conferenza New Hampshire\n","x":-193,"y":97,"width":584,"height":61},
		{"id":"ac374fff889d52b8","type":"text","text":"Intellgienza Artificiale Debole\n---\nPuò svolgere solo il compito per compito per cui è stata progettata\n\n**Esempi di applicazione:**\n- Riconoscimento vocale,\n- Elaborazione delle immagini \n- Elaborazione del linguaggio naturale.\n\n**Limiti:**\n- Può fornire risposte solo sul set di dati (dominio) su cui è stato costruito\n- Non può adattarsi a nuove situazioni\n- Non è in grado di apprendere nuove informazioni\n\n**Vantaggi:**\n- Più semplice da sviluppare rispetto alla AI forte\n- Esecuzione più rapida e accurata dei compiti rispetto agli esseri umani, ideale per attività ripetitive, noiose o pericolose.","x":-1880,"y":-440,"width":416,"height":814},
		{"id":"88311a0b1bdbf788","type":"text","text":"Intellgienza Artificiale Forte\n---\nNota anche come \"Intelligenza artificiale generica (AGI)\" si pone l'obiettivo di avere come modello le capacità cognitive di un essere umano\n\n**Esempi di applicazione:**\n- Riconoscimento di oggetti in un'immagine, \n- Riconoscimento  e classificazione di oggetti che non ha mai visto prima\n\n**Vantaggi:**\n- Non ha un dominio di applicazioni limitato\n- Può apprendere cose nuove e migliorarsi autonomamente\n- Può generalizzare dai dati di addestramento e applicare le sue conoscenze a nuove situazioni\n- Potenziale di raggiungere e superare l'intelligenza umana, portando a progressi significativi in medicina, scienza ed ingegneria.\n\n**Contro:**\n- Necessità di utilizzare delle misure di sicurezza e sviluppare l'AI seguendo dei criteri etici.\n- Sostituizione dei posti di lavoro e manovalanza","x":-1400,"y":-440,"width":454,"height":814},
		{"id":"bb61fa7da349633c","type":"text","text":"Test di Turing\n---\n>\"Un computer è da considerarsi intelligente se, nell'interazione a distanza con un essere umano, non è in grado di distinguere se sta interagendo con un uomo o una macchina.\"\n\nNasce nel 1950, pubblicato in un articolo chiamato \"Computing Machinery and Intelligence.\", dal matematico Alan Turing.\n\n**Funzionamento:** \nCoinvolge tre partecipanti umani. Uno di questi è l'interrogatore, che pone domande sia a un essere umano che a una macchina (o a un programma) nascosta in un'altra stanza. L'obiettivo dell'interrogatore è determinare quale delle due risposte proviene dalla macchina e quale dall'essere umano. La macchina cerca di ingannare l'interrogatore cercando di rispondere in modo indistinguibile da un essere umano.\nSe la macchina riesce a ingannare regolarmente l'interrogatore, si può sostenere che la macchina dimostra un comportamento intelligente.\n\n- È stato un contributo fondamentale alla filosofia e all'etica dell'intelligenza artificiale.\n- Non verifica la capacità di dare risposte corrette alle domande, ma solo come queste risposte assomigliano a quelle che darebbe un essere umano.\n","x":-1880,"y":440,"width":940,"height":460},
		{"id":"52a30a7be969a314","type":"text","text":"Cos'è una strategia di ricerca?\n---\nLa scelta di quale stato espandere nell'albero di ricerca\nDistinguiamo:\n- Strategie di ricerca informata\n- Strategie di ricerca non informata","x":-5760,"y":-1640,"width":540,"height":360},
		{"id":"079e1ebd1533d9ff","type":"text","text":"Breadth-first (Ricerca in ampiezza)\n---\n**Struttura dati:** Coda, è un algoritmo di tipo FIFO\n**Complessità spaziale:** $O(b^d)$\nComplessità temporale: $O(b^d)$\n\tDove b è il fattore di ramificazione (numero massimo di figli di un nodo) e d rappresenta la profondità \n**Completezza:** è considerato un algoritmo completo in quanto visita in ordine tutti i nodi del grafo","x":-4260,"y":-1240,"width":520,"height":420},
		{"id":"7f2e66c2401b7575","type":"text","text":"Depth-first (Ricerca in profondità)\n---\n**Struttura dati:** Coda, è un algoritmo di tipo FIFO\n**Complessità spaziale:** $O(b^m)$\nComplessità temporale: $O(b\\cdot m)$\n\tDove b è il fattore di ramificazione (numero massimo di figli di un nodo) e m rappresenta la  massima profondità \nCompletezza: non è completo perché può imbattersi in un percorso di profondità infinita\n**Ottimalità:** non è ottimo perché non usa nessun criterio per favorire le soluzioni a costo minore","x":-3700,"y":-1240,"width":520,"height":420},
		{"id":"f97c3c5e269dc70c","type":"text","text":"Depth-first search con backtracking\n---\n**Struttura dati:** Coda, è un algoritmo di tipo FIFO\n**Complessità spaziale:** $O(b^d)$\nComplessità temporale: $O(b^d)$\n\tDove b è il fattore di ramificazione (numero massimo di figli di un nodo) e d rappresenta la profondità \n","x":-3700,"y":-570,"width":520,"height":420},
		{"id":"33f0d6a969b00e90","type":"text","text":"Depth-Limited Search\n---\nVariazione della DFS che introduce un limite alla profondità per ovviare al problema degli alberi con rami di profondità infinita\n**Struttura dati:** Coda, è un algoritmo di tipo FIFO\n**Complessità spaziale:** $O(b^d)$\nComplessità temporale: $O(b^d)$\n\tDove b è il fattore di ramificazione (numero massimo di figli di un nodo) e d rappresenta la profondità \n**Completezza**:\n**Ottimalità:** è ","x":-3140,"y":-570,"width":520,"height":420},
		{"id":"7391b1910949bf68","type":"text","text":"Uniform Cost Search\n---\n**Struttura dati:** Coda, è un algoritmo di tipo FIFO\n**Complessità spaziale:** $O(b^d)$\nComplessità temporale: $O(b^d)$\n\tDove b è il fattore di ramificazione (numero massimo di figli di un nodo) e d rappresenta la profondità \n","x":-4260,"y":-780,"width":520,"height":420},
		{"id":"4e625539f042b4d2","type":"text","text":"Richiami di algoritmi e strutture dati:\n---\n- Il fattore di ramificiazione rappresenta il numero massimo di figli di un nodo, è il fattore d negli alberi d-ari, per non confondersi con la d di depth, in questo contesto viene indicato con la lettera \"b\".\n- Il numero di massimo di nodi di un albero con profondità \"d\" e fattore di ramificazione \"b\" è dato dalla sommatoria delle potenze i-esime di b con i che va da 0-b\n\n$$b^0+b^1+b^2+...b^d=\\sum_{i=0}^db^i$$","x":-4260,"y":-1640,"width":520,"height":360},
		{"id":"377a196b2405c675","type":"text","text":"Strategia di ricerca informata (Ricerca euristica)\n---\n- Fa uso di informazioni specifiche sul problema per guidare la ricerca verso la soluzione desiderata in modo più efficiente.\n- Gli algoritmi di ricerca euristica utilizzano euristiche o valutazioni delle soluzioni parziali per valutare la promessa di una determinata strada o azione.\n\n Esempi di algoritmi di ricerca informata includono l'algoritmo A* (A-Star) e la ricerca di prima scelta (Best-First Search).\n","x":-5760,"y":-1200,"width":540,"height":360},
		{"id":"b6a0686f506b3c1c","type":"text","text":"Strategia di ricerca non informata (Blind search)\n---\n- Si basa su algoritmi di ricerca che non utilizzano alcuna conoscenza specifica del problema o euristiche per guidare il processo decisionale.\n- Gli algoritmi di blind search esplorano lo spazio delle soluzioni senza sapere nulla in anticipo su quale strada sia la migliore da percorrere. Si tratta di metodi di prova ed errore.\n\n1. Breadth-First\n2. Depth-first\n3. Depth-first a profondità limitata\n4. Ad approfondimento iterativo","x":-5180,"y":-1200,"width":540,"height":380},
		{"id":"b91e40c8276c8d24","type":"text","text":"Valutazione\n---\nVi sono diversi parametri per valutare la strategia di ricerca di un agente\n\n**Completezza**: l’algoritmo garantisce di trovare una soluzione, se questa esiste?\n**Complessità temporale:** quanto tempo è necessario per raggiungerla?\n**Complessità spaziale**: quanta memoria è richiesta per raggiungerla ?\n**Ottimalità:** la soluzione trovata è la migliore (a costo minimo) quando ci sono varie soluzioni differenti?\n","x":-5757,"y":-780,"width":907,"height":320},
		{"id":"6760dc4a21f6a16f","type":"text","text":"Algoritmo completo\n---\nGli algoritmi completi esplorano tutte le possibili soluzioni in modo sistematico per determinare se una soluzione migliore o l'ottimo esiste o meno\n\n**Contro:** possono richiedere tempo esponenziale per trovare la soluzione. ","x":-5757,"y":-315,"width":341,"height":298},
		{"id":"5108aaee389e45f1","type":"text","text":"Algoritmo ottimo\n---\nUn \"algoritmo ottimo\" è un algoritmo che fornisce la soluzione migliore o l'ottimo globale per un dato problema di ottimizzazione. In altre parole, è un algoritmo che trova la soluzione che massimizza o minimizza la funzione obiettivo in modo perfetto, senza possibilità di miglioramento. Tuttavia, trovare un algoritmo ottimo è spesso impossibile per molti problemi complessi, e si deve spesso fare affidamento su algoritmi approssimati o euristiche.","x":-5310,"y":-315,"width":320,"height":298},
		{"id":"ff791336e7bb2c60","type":"text","text":"Algoritmo non ottimo\n---\nPuò fornire una soluzione al problema di ottimizzazione, ma questa soluzione potrebbe non essere la migliore possibile. \n\n**Utilizzo:** quando la soluzione ottima richiede troppo tempo o troppe risorse per poter essere trovata","x":-4910,"y":-315,"width":320,"height":298},
		{"id":"438eb63dd76eb548","type":"text","text":"Funzione euristica\n---\nCon euristica si intende stima o soluzione parziale, ritorna molto utile in quanto sulla base dell'euristica fornita, viene creata una coda con priorità che ricerca prima ne soluzioni con probabilità più alta","x":-6391,"y":-854,"width":331,"height":254},
		{"id":"71a982f18b756f6c","type":"text","text":"Una soluzione è un cammino che conduce ad un insieme di stati (sottoinsieme dello spazio degli stati) che sono tutti stati obiettivo.","x":-6511,"y":2881,"width":250,"height":250},
		{"id":"121c881c1e284522","type":"text","text":"Una soluzione è una sequenza di operatori che conducono dallo stato iniziale ad uno stato obiettivo","x":-6511,"y":2243,"width":250,"height":193},
		{"id":"c9cc6f3e0ff23f58","type":"text","text":"2. **Agenti riflessi con stato:** Questi agenti mantengono una rappresentazione interna dello stato corrente dell'ambiente o di sé stessi. Utilizzano queste rappresentazioni per prendere decisioni più sofisticate, considerando il contesto storico e le esperienze passate. In altre parole, tengono traccia dello stato e delle informazioni passate per guidare le loro azioni presenti. Gli agenti riflessi con stato sono più adattabili e in grado di gestire situazioni complesse rispetto ai semplici agenti riflessi.","x":-15499,"y":-2885,"width":400,"height":399}
	],
	"edges":[
		{"id":"185e5822964a15af","fromNode":"fef80b7c87bac4c1","fromSide":"bottom","toNode":"80598154a9bb1888","toSide":"top"},
		{"id":"2a38c71a7e067a19","fromNode":"fef80b7c87bac4c1","fromSide":"bottom","toNode":"3536d34be9bcffaf","toSide":"top"},
		{"id":"53b3e6bf3dc5455b","fromNode":"80598154a9bb1888","fromSide":"bottom","toNode":"cc2724deb52c9e41","toSide":"top"},
		{"id":"80d2e3e86bd97fff","fromNode":"3536d34be9bcffaf","fromSide":"bottom","toNode":"c1feae09229e4a8a","toSide":"top"},
		{"id":"97c0a3d407b267f5","fromNode":"cc2724deb52c9e41","fromSide":"bottom","toNode":"5e2d26a4d9bd0e8a","toSide":"top"},
		{"id":"88f51e3175b5d893","fromNode":"c1feae09229e4a8a","fromSide":"bottom","toNode":"5e2d26a4d9bd0e8a","toSide":"top"},
		{"id":"bb8a63af7c6541ff","fromNode":"5e2d26a4d9bd0e8a","fromSide":"bottom","toNode":"e0f409d4f08ae900","toSide":"top"},
		{"id":"549a9d43f7e34408","fromNode":"6418a73b07f7b097","fromSide":"bottom","toNode":"3c1398ccff64db63","toSide":"left"},
		{"id":"7ceeb7e74eb8bd7a","fromNode":"6418a73b07f7b097","fromSide":"bottom","toNode":"7f2d3c8bb821c29e","toSide":"left"},
		{"id":"20ed97113e150b1b","fromNode":"6418a73b07f7b097","fromSide":"bottom","toNode":"ca4c1c1d164f0da4","toSide":"left"},
		{"id":"8cb5735cf6f3ca88","fromNode":"b91e40c8276c8d24","fromSide":"bottom","toNode":"6760dc4a21f6a16f","toSide":"top"},
		{"id":"d85a8212a5297dc6","fromNode":"b91e40c8276c8d24","fromSide":"bottom","toNode":"5108aaee389e45f1","toSide":"top"},
		{"id":"05624b675864108f","fromNode":"b91e40c8276c8d24","fromSide":"bottom","toNode":"ff791336e7bb2c60","toSide":"top"},
		{"id":"e1c1d9fbf6bd3abd","fromNode":"52a30a7be969a314","fromSide":"bottom","toNode":"377a196b2405c675","toSide":"top"},
		{"id":"a37b4e83ebe6c15b","fromNode":"52a30a7be969a314","fromSide":"bottom","toNode":"b6a0686f506b3c1c","toSide":"top"},
		{"id":"f3b3e615037efd09","fromNode":"b6a0686f506b3c1c","fromSide":"right","toNode":"079e1ebd1533d9ff","toSide":"left"},
		{"id":"afcf1310fad9a496","fromNode":"079e1ebd1533d9ff","fromSide":"bottom","toNode":"7391b1910949bf68","toSide":"top"},
		{"id":"4da5a8c21aac4abe","fromNode":"7f2e66c2401b7575","fromSide":"bottom","toNode":"f97c3c5e269dc70c","toSide":"top"},
		{"id":"e90703a31a6435b3","fromNode":"7f2e66c2401b7575","fromSide":"bottom","toNode":"33f0d6a969b00e90","toSide":"top"},
		{"id":"595922c0c5a637e0","fromNode":"377a196b2405c675","fromSide":"bottom","toNode":"438eb63dd76eb548","toSide":"top"},
		{"id":"778359cb36f88bc2","fromNode":"f436bf0c14132662","fromSide":"bottom","toNode":"f8b987ffd135f0bd","toSide":"top"},
		{"id":"596903ee1f428b20","fromNode":"f436bf0c14132662","fromSide":"bottom","toNode":"b284f33974a74b4a","toSide":"top"},
		{"id":"bea24683aa630861","fromNode":"62356168bc82e293","fromSide":"right","toNode":"978773b970fed2b9","toSide":"left"},
		{"id":"fcbf0f8cd254bda6","fromNode":"f3b3e9c3ebf18a98","fromSide":"bottom","toNode":"2b0f00f9e2ed9114","toSide":"left"},
		{"id":"79737b64d28242b9","fromNode":"f3b3e9c3ebf18a98","fromSide":"bottom","toNode":"ba813fab1efda65c","toSide":"left"},
		{"id":"fd4076db73158758","fromNode":"f3b3e9c3ebf18a98","fromSide":"bottom","toNode":"a253e24b36d5b006","toSide":"left"},
		{"id":"615682e0f235d65a","fromNode":"f3b3e9c3ebf18a98","fromSide":"bottom","toNode":"9c4a99074a66f325","toSide":"left"},
		{"id":"da65ec64dd6412a9","fromNode":"0f0c42ee452422f5","fromSide":"bottom","toNode":"f3b3e9c3ebf18a98","toSide":"left"},
		{"id":"98be0f53951eb08a","fromNode":"ba813fab1efda65c","fromSide":"right","toNode":"df311ca290c21107","toSide":"left"},
		{"id":"8905eb3d299ab297","fromNode":"17e04cc6b652cee1","fromSide":"right","toNode":"71a982f18b756f6c","toSide":"left","label":"Soluzione"},
		{"id":"43c67c32207f03f6","fromNode":"2b0f00f9e2ed9114","fromSide":"right","toNode":"17e04cc6b652cee1","toSide":"left"},
		{"id":"97099312cb09c775","fromNode":"df311ca290c21107","fromSide":"right","toNode":"121c881c1e284522","toSide":"left","label":"Soluzione"},
		{"id":"7854e86a670bbdbf","fromNode":"a253e24b36d5b006","fromSide":"right","toNode":"1aefccf17e8aa852","toSide":"left"},
		{"id":"91a5b7e1b5ea6d83","fromNode":"1aefccf17e8aa852","fromSide":"right","toNode":"3c9803641bc94e71","toSide":"left"}
	]
}